Name: Shivraj Mahesh Shelar Roll No: 3019 
Output: Hive Analytics (in Cloudera) 
 
[cloudera@quickstart ~]$ hdfs dfs -mkdir -p /Cloudera 
[cloudera@quickstart ~]$ hdfs dfs -put /home/cloudera/Desktop/FromWindows/flight_info.csv 
[cloudera@quickstart ~]$ hdfs dfs -put /home/cloudera/Desktop/FromWindows/flight_info.csv 
/Cloudera 
[cloudera@quickstart ~]$ clear 
 
[cloudera@quickstart ~]$ hive 
 
Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j.properties 
WARNING: Hive CLI is deprecated and migration to Beeline is recommended. 
hive> create database flight_db; 
OK 
Time taken: 0.961 seconds 
hive> use flight_db; 
OK 
Time taken: 0.041 seconds 
 
Create External Table:  
hive> create external table flight_info ( 
    > year INT, 
    >    month INT, 
    >    day INT, 
    >    day_of_week INT, 
    >    dep_time INT, 
    >    crs_dep_time INT, 
    >    arr_time INT, 
    >    crs_arr_time INT, 
    >    unique_carrier STRING, 
    >    flight_num INT, 
    >    tail_num STRING, 
    >    actual_elapsed_time INT, 
    >    crs_elapsed_time INT, 
    >    air_time INT, 
    >    arr_delay INT, 
    >    dep_delay INT, 
    >    origin STRING, 
    >    dest STRING, 
    >    distance INT, 
    >    taxi_in INT, 
    >    taxi_out INT, 
    >    cancelled INT, 
    >    cancellation_code STRING, 
    >    diverted INT, 
    >    carrier_delay STRING, 
    >    weather_delay STRING, 
    >    nas_delay STRING, 
    >    security_delay STRING, 
    >    late_aircraft_delay STRING 
    > ) 
    > row format delimited 
    > fields terminated by ',' 
    > stored as textfile 
    > location '/Cloudera' 
    > ; 
OK 
Time taken: 0.621 seconds 
 
Create Another Table: 
hive> create table flight_summary AS 
    > select 
    > year,month,day,unique_carrier,flight_num,dep_delay,origin,dest 
    > FROM flight_info; 
Query ID = cloudera_20250424094343_cffa5932-13c2-4e5f-914a-98c04aeba9e7 
Total jobs = 3 
Launching Job 1 out of 3 
Number of reduce tasks is set to 0 since there's no reduce operator 
Starting Job = job_1745510808926_0001, Tracking URL = 
http://quickstart.cloudera:8088/proxy/application_1745510808926_0001/ 
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1745510808926_0001 
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0 
2025-04-24 09:43:44,427 Stage-1 map = 0%,  reduce = 0% 
2025-04-24 09:44:01,098 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.16 sec 
MapReduce Total cumulative CPU time: 3 seconds 160 msec 
Ended Job = job_1745510808926_0001 
Stage-4 is selected by condition resolver. 
Stage-3 is filtered out by condition resolver. 
Stage-5 is filtered out by condition resolver. 
Moving data to: 
hdfs://quickstart.cloudera:8020/user/hive/warehouse/flight_db.db/.hive-staging_hive_2025-04-2
 4_09-43-22_194_8011609306054582379-1/-ext-10001 
Moving data to: 
hdfs://quickstart.cloudera:8020/user/hive/warehouse/flight_db.db/flight_summary 
Table flight_db.flight_summary stats: [numFiles=1, numRows=257250, totalSize=7263079, 
rawDataSize=7005829] 
MapReduce Jobs Launched:  
Stage-Stage-1: Map: 1   Cumulative CPU: 3.16 sec   HDFS Read: 25119661 HDFS Write: 
7263168 SUCCESS 
Total MapReduce CPU Time Spent: 3 seconds 160 msec 
OK 
Time taken: 42.303 seconds 
 
Alter Table: 
hive> alter table flight_summary ADD columns (flight_code STRING); 
OK 
Time taken: 0.216 seconds 
hive> insert overwrite table flight_summary 
    > select 
    > year, 
    > month, 
    > day, 
    > unique_carrier, 
    > flight_num 
    > , 
    > dep_delay, 
    > origin, 
    > dest, 
    > CONCAT(unique_carrier, CAST(flight_num AS STRING)) AS flight_code 
    > FROM flight_summary; 
Query ID = cloudera_20250424094747_9325eb5a-414f-47c9-a683-2671c7aa31d3 
Total jobs = 3 
Launching Job 1 out of 3 
Number of reduce tasks is set to 0 since there's no reduce operator 
Starting Job = job_1745510808926_0002, Tracking URL = 
http://quickstart.cloudera:8088/proxy/application_1745510808926_0002/ 
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1745510808926_0002 
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0 
2025-04-24 09:47:28,043 Stage-1 map = 0%,  reduce = 0% 
2025-04-24 09:47:45,785 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 5.87 sec 
MapReduce Total cumulative CPU time: 5 seconds 870 msec 
Ended Job = job_1745510808926_0002 
Stage-4 is selected by condition resolver. 
Stage-3 is filtered out by condition resolver. 
Stage-5 is filtered out by condition resolver. 
Moving data to: 
hdfs://quickstart.cloudera:8020/user/hive/warehouse/flight_db.db/flight_summary/.hive-staging_
 hive_2025-04-24_09-47-12_330_9025852676339288380-1/-ext-10000 
Loading data to table flight_db.flight_summary 
Table flight_db.flight_summary stats: [numFiles=1, numRows=257250, totalSize=8983569, 
rawDataSize=8726319] 
MapReduce Jobs Launched:  
Stage-Stage-1: Map: 1   Cumulative CPU: 5.87 sec   HDFS Read: 7267923 HDFS Write: 
8983658 SUCCESS 
Total MapReduce CPU Time Spent: 5 seconds 870 msec 
OK 
Time taken: 36.5 seconds 
Insertion in Table: 
hive> INSERT INTO TABLE flight_summary VALUES( 
> 2023,12,31,'AA',101,25,'JFK','LAX','AA101' 
> ); 
Query ID = cloudera_20250424094949_4b87130e-33c7-48d0-98aa-1668ffd593ec 
Total jobs = 3 
Launching Job 1 out of 3 
Number of reduce tasks is set to 0 since there's no reduce operator 
Starting Job = job_1745510808926_0003, Tracking URL = 
http://quickstart.cloudera:8088/proxy/application_1745510808926_0003/ 
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1745510808926_0003 
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0 
2025-04-24 09:49:31,900 Stage-1 map = 0%,  reduce = 0% 
2025-04-24 09:49:43,643 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.33 sec 
MapReduce Total cumulative CPU time: 2 seconds 330 msec 
Ended Job = job_1745510808926_0003 
Stage-4 is selected by condition resolver. 
Stage-3 is filtered out by condition resolver. 
Stage-5 is filtered out by condition resolver. 
Moving data to: 
hdfs://quickstart.cloudera:8020/user/hive/warehouse/flight_db.db/flight_summary/.hive-staging_
 hive_2025-04-24_09-49-17_216_3273532785595310936-1/-ext-10000 
Loading data to table flight_db.flight_summary 
Table flight_db.flight_summary stats: [numFiles=2, numRows=257251, totalSize=8983604, 
rawDataSize=8726353] 
MapReduce Jobs Launched:  
Stage-Stage-1: Map: 1   Cumulative CPU: 2.33 sec   HDFS Read: 5481 HDFS Write: 115 
SUCCESS 
Total MapReduce CPU Time Spent: 2 seconds 330 msec 
OK 
Time taken: 29.28 seconds 
Create Index on Table: 
hive> CREATE INDEX delay_index 
> ON TABLE flight_summary (dep_delay) 
> AS 'COMPACT' 
> WITH deferred rebuild; 
OK 
Time taken: 0.465 seconds 
hive> ALTER INDEX delay_index ON flight_summary REBUILD; 
Query ID = cloudera_20250424095151_aa521f31-c38b-43ab-a64e-79e9af527b42 
Total jobs = 1 
Launching Job 1 out of 1 
Number of reduce tasks not specified. Estimated from input data size: 1 
In order to change the average load for a reducer (in bytes): 
set hive.exec.reducers.bytes.per.reducer=<number> 
In order to limit the maximum number of reducers: 
set hive.exec.reducers.max=<number> 
In order to set a constant number of reducers: 
set mapreduce.job.reduces=<number> 
Starting Job = job_1745510808926_0004, Tracking URL = 
http://quickstart.cloudera:8088/proxy/application_1745510808926_0004/ 
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1745510808926_0004 
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1 
2025-04-24 09:51:39,370 Stage-1 map = 0%,  reduce = 0% 
2025-04-24 09:51:50,260 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.66 sec 
2025-04-24 09:52:03,452 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 6.74 sec 
MapReduce Total cumulative CPU time: 6 seconds 740 msec 
Ended Job = job_1745510808926_0004 
Loading data to table flight_db.flight_db__flight_summary_delay_index__ 
Table flight_db.flight_db__flight_summary_delay_index__ stats: [numFiles=1, numRows=495, 
totalSize=2071031, rawDataSize=2070536] 
MapReduce Jobs Launched:  
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 6.74 sec   HDFS Read: 8993666 HDFS 
Write: 2071142 SUCCESS 
Total MapReduce CPU Time Spent: 6 seconds 740 msec 
OK 
Time taken: 38.664 seconds 
Calculate Average delay of Departure (according to DATE): 
hive> SELECT year,month,day, AVG(dep_delay) AS avg_dep_delay 
> FROM flight_summary 
> WHERE dep_delay IS NOT NULL 
> GROUP BY year,month,day 
> ORDER BY year,month,day; 
Query ID = cloudera_20250424095454_2dfc4825-126c-4092-bba2-1d7b09b41699 
Total jobs = 2 
Launching Job 1 out of 2 
Number of reduce tasks not specified. Estimated from input data size: 1 
In order to change the average load for a reducer (in bytes): 
set hive.exec.reducers.bytes.per.reducer=<number> 
In order to limit the maximum number of reducers: 
set hive.exec.reducers.max=<number> 
In order to set a constant number of reducers: 
set mapreduce.job.reduces=<number> 
Starting Job = job_1745510808926_0005, Tracking URL = 
http://quickstart.cloudera:8088/proxy/application_1745510808926_0005/ 
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1745510808926_0005 
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1 
2025-04-24 09:54:36,722 Stage-1 map = 0%,  reduce = 0% 
2025-04-24 09:54:45,008 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.33 sec 
2025-04-24 09:54:53,681 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.51 sec 
MapReduce Total cumulative CPU time: 3 seconds 510 msec 
Ended Job = job_1745510808926_0005 
Launching Job 2 out of 2 
Number of reduce tasks determined at compile time: 1 
In order to change the average load for a reducer (in bytes): 
set hive.exec.reducers.bytes.per.reducer=<number> 
In order to limit the maximum number of reducers: 
set hive.exec.reducers.max=<number> 
In order to set a constant number of reducers: 
set mapreduce.job.reduces=<number> 
Starting Job = job_1745510808926_0006, Tracking URL = 
http://quickstart.cloudera:8088/proxy/application_1745510808926_0006/ 
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1745510808926_0006 
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1 
2025-04-24 09:55:06,909 Stage-2 map = 0%,  reduce = 0% 
2025-04-24 09:55:14,396 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.76 sec 
2025-04-24 09:55:25,668 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 4.11 sec 
MapReduce Total cumulative CPU time: 4 seconds 110 msec 
Ended Job = job_1745510808926_0006 
MapReduce Jobs Launched:  
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.51 sec   HDFS Read: 8992575 HDFS 
Write: 1056 SUCCESS 
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 4.11 sec   HDFS Read: 6772 HDFS Write: 
891 SUCCESS 
Total MapReduce CPU Time Spent: 7 seconds 620 msec 
OK 
2008 1 
1 
2008 1 
2008 1 
2008 1 
2008 1 
2008 1 
2008 1 
2 
3 
4 
5 
6 
7 
17.57681842916742 
23.900056359195943 
19.370313695485844 
18.612678509230232 
25.976967114898148 
22.146653781106547 
14.395251396648044 
2008 1 8 12.124760306807287 
2008 1 9 5.839149336153214 
2008 1 10 9.223829201101928 
2008 1 11 9.410679275746743 
2008 1 12 1.6842865395725015 
2008 1 13 6.079343193782903 
2008 1 14 4.633204633204633 
2008 1 15 5.640961857379768 
2008 1 16 1.9354166666666666 
2008 1 17 18.21534910559723 
2008 1 18 12.01187917185202 
2008 1 19 7.5900463308922435 
2008 1 20 6.213233458177278 
2008 1 21 25.198426472289714 
2008 1 22 17.538498383427136 
2008 1 23 11.585463541053128 
2008 1 24 9.975531671621313 
2008 1 25 14.944508404328804 
2008 1 26 4.631294964028777 
2008 1 27 25.05219499744768 
2008 1 28 14.486067019400354 
2008 1 29 9.989655592065231 
2008 1 30 6.108780661215784 
2008 1 31 27.131638620360423 
2023 12 31 25.0 
Time taken: 64.086 seconds, Fetched: 32 row(s) 
 
Setting header=true (to display headers): 
hive> set hive.cli.print.header=true; 
hive> SELECT year,month,day, AVG(dep_delay) AS avg_dep_delay 
    > FROM flight_summary 
    > WHERE dep_delay IS NOT NULL 
    > GROUP BY year,month,day 
    > ORDER BY year,month,day; 
Query ID = cloudera_20250424095959_ff5a8699-25d1-45d9-832e-82eecf9cbc7d 
Total jobs = 2 
Launching Job 1 out of 2 
Number of reduce tasks not specified. Estimated from input data size: 1 
In order to change the average load for a reducer (in bytes): 
  set hive.exec.reducers.bytes.per.reducer=<number> 
In order to limit the maximum number of reducers: 
  set hive.exec.reducers.max=<number> 
In order to set a constant number of reducers: 
  set mapreduce.job.reduces=<number> 
Starting Job = job_1745510808926_0007, Tracking URL = 
http://quickstart.cloudera:8088/proxy/application_1745510808926_0007/ 
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1745510808926_0007 
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1 
2025-04-24 09:59:29,037 Stage-1 map = 0%,  reduce = 0% 
2025-04-24 09:59:38,888 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.28 sec 
2025-04-24 09:59:49,557 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.61 sec 
MapReduce Total cumulative CPU time: 4 seconds 610 msec 
Ended Job = job_1745510808926_0007 
Launching Job 2 out of 2 
Number of reduce tasks determined at compile time: 1 
In order to change the average load for a reducer (in bytes): 
set hive.exec.reducers.bytes.per.reducer=<number> 
In order to limit the maximum number of reducers: 
set hive.exec.reducers.max=<number> 
In order to set a constant number of reducers: 
set mapreduce.job.reduces=<number> 
Starting Job = job_1745510808926_0008, Tracking URL = 
http://quickstart.cloudera:8088/proxy/application_1745510808926_0008/ 
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1745510808926_0008 
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1 
2025-04-24 10:00:02,168 Stage-2 map = 0%,  reduce = 0% 
2025-04-24 10:00:09,803 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.1 sec 
2025-04-24 10:00:17,536 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 2.74 sec 
MapReduce Total cumulative CPU time: 2 seconds 740 msec 
Ended Job = job_1745510808926_0008 
MapReduce Jobs Launched:  
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.61 sec   HDFS Read: 8992575 HDFS 
Write: 1056 SUCCESS 
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 2.74 sec   HDFS Read: 6772 HDFS 
Write: 891 SUCCESS 
Total MapReduce CPU Time Spent: 7 seconds 350 msec 
OK 
Print Average Departure Delay (with header): 
year month day avg_dep_delay 
2008 1 
1 
2008 1 
2008 1 
2008 1 
2008 1 
2008 1 
2008 1 
2008 1 
2 
3 
4 
5 
6 
7 
8 
17.57681842916742 
23.900056359195943 
19.370313695485844 
18.612678509230232 
25.976967114898148 
22.146653781106547 
14.395251396648044 
12.124760306807287 
2008 1 9 5.839149336153214 
2008 1 10 9.223829201101928 
2008 1 11 9.410679275746743 
2008 1 12 1.6842865395725015 
2008 1 13 6.079343193782903 
2008 1 14 4.633204633204633 
2008 1 15 5.640961857379768 
2008 1 16 1.9354166666666666 
2008 1 17 18.21534910559723 
2008 1 18 12.01187917185202 
2008 1 19 7.5900463308922435 
2008 1 20 6.213233458177278 
2008 1 21 25.198426472289714 
2008 1 22 17.538498383427136 
2008 1 23 11.585463541053128 
2008 1 24 9.975531671621313 
2008 1 25 14.944508404328804 
2008 1 26 4.631294964028777 
2008 1 27 25.05219499744768 
2008 1 28 14.486067019400354 
2008 1 29 9.989655592065231 
2008 1 30 6.108780661215784 
2008 1 31 27.131638620360423 
2023 12 31 25.0 
Time taken: 63.252 seconds, Fetched: 32 row(s) 
 
Average departure delay (only dep_delay cloumn): 
hive> select AVG(dep_delay) from flight_summary; 
Query ID = cloudera_20250424100101_16923b32-cf98-4516-b196-ab2d9296b91b 
Total jobs = 1 
Launching Job 1 out of 1 
Number of reduce tasks determined at compile time: 1 
In order to change the average load for a reducer (in bytes): 
  set hive.exec.reducers.bytes.per.reducer=<number> 
In order to limit the maximum number of reducers: 
  set hive.exec.reducers.max=<number> 
In order to set a constant number of reducers: 
  set mapreduce.job.reduces=<number> 
Starting Job = job_1745510808926_0009, Tracking URL = 
http://quickstart.cloudera:8088/proxy/application_1745510808926_0009/ 
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1745510808926_0009 
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1 
2025-04-24 10:01:20,173 Stage-1 map = 0%,  reduce = 0% 
2025-04-24 10:01:28,640 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.77 sec 
2025-04-24 10:01:41,748 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 6.28 sec 
MapReduce Total cumulative CPU time: 6 seconds 280 msec 
Ended Job = job_1745510808926_0009 
MapReduce Jobs Launched:  
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 6.28 sec   HDFS Read: 8992591 HDFS 
Write: 19 SUCCESS 
Total MapReduce CPU Time Spent: 6 seconds 280 msec 
OK 
_c0 
13.104527062217059 
Time taken: 33.647 seconds, Fetched: 1 row(s) 
hive>  